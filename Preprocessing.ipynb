{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"preprocessing_data","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!python -m pip install --upgrade spacy\n","!python -m spacy download es_core_news_sm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fl_kYoZRbUpy","executionInfo":{"status":"ok","timestamp":1648703243979,"user_tz":-120,"elapsed":44659,"user":{"displayName":"Jose Miguel Hernandez Cabrera","userId":"08063937864922179912"}},"outputId":"fae43407-c35e-4b84-a437-59962750d664"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n","Collecting spacy\n","  Downloading spacy-3.2.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n","\u001b[K     |████████████████████████████████| 6.0 MB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n","Collecting langcodes<4.0.0,>=3.2.0\n","  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 44.8 MB/s \n","\u001b[?25hCollecting thinc<8.1.0,>=8.0.12\n","  Downloading thinc-8.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (653 kB)\n","\u001b[K     |████████████████████████████████| 653 kB 36.5 MB/s \n","\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n","Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.1.2)\n","Collecting pathy>=0.3.5\n","  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n","\u001b[K     |████████████████████████████████| 42 kB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.63.0)\n","Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n","  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n","\u001b[K     |████████████████████████████████| 10.1 MB 23.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n","Collecting spacy-loggers<2.0.0,>=1.0.0\n","  Downloading spacy_loggers-1.0.2-py3-none-any.whl (7.2 kB)\n","Collecting spacy-legacy<3.1.0,>=3.0.8\n","  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.5)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n","Collecting srsly<3.0.0,>=2.4.1\n","  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n","\u001b[K     |████████████████████████████████| 451 kB 38.1 MB/s \n","\u001b[?25hCollecting catalogue<2.1.0,>=2.0.6\n","  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n","Collecting typer<0.5.0,>=0.3.0\n","  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.7.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.7)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n","Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n","  Attempting uninstall: catalogue\n","    Found existing installation: catalogue 1.0.0\n","    Uninstalling catalogue-1.0.0:\n","      Successfully uninstalled catalogue-1.0.0\n","  Attempting uninstall: srsly\n","    Found existing installation: srsly 1.0.5\n","    Uninstalling srsly-1.0.5:\n","      Successfully uninstalled srsly-1.0.5\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 7.4.0\n","    Uninstalling thinc-7.4.0:\n","      Successfully uninstalled thinc-7.4.0\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 2.2.4\n","    Uninstalling spacy-2.2.4:\n","      Successfully uninstalled spacy-2.2.4\n","Successfully installed catalogue-2.0.7 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 spacy-3.2.4 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.2 thinc-8.0.15 typer-0.4.1\n","Collecting es-core-news-sm==3.2.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.2.0/es_core_news_sm-3.2.0-py3-none-any.whl (14.0 MB)\n","\u001b[K     |████████████████████████████████| 14.0 MB 5.5 MB/s \n","\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from es-core-news-sm==3.2.0) (3.2.4)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (2.0.6)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (0.4.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (2.11.3)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (1.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (21.3)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (1.21.5)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (3.3.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (3.0.6)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (3.10.0.2)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (1.8.2)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (8.0.15)\n","Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (7.1.2)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (3.0.9)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (1.0.6)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (2.23.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (57.4.0)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (0.6.1)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (0.9.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (2.4.2)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (0.4.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (2.0.7)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (4.63.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (3.7.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (3.0.7)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (5.2.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (2021.10.8)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->es-core-news-sm==3.2.0) (2.0.1)\n","Installing collected packages: es-core-news-sm\n","Successfully installed es-core-news-sm-3.2.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('es_core_news_sm')\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QgOS3hxgMcNA","executionInfo":{"status":"ok","timestamp":1648703273026,"user_tz":-120,"elapsed":29055,"user":{"displayName":"Jose Miguel Hernandez Cabrera","userId":"08063937864922179912"}},"outputId":"a9e14328-9934-4d18-b516-78391d36b508"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package perluniprops to /root/nltk_data...\n","[nltk_data]   Unzipping misc/perluniprops.zip.\n","[nltk_data] Downloading package nonbreaking_prefixes to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","Mounted at /content/drive/\n"]}],"source":["import string\n","\n","import nltk\n","import spacy\n","import pandas as pd\n","\n","from pathlib import Path\n","from collections import Counter\n","\n","from nltk.tokenize.casual import TweetTokenizer\n","from nltk.corpus import stopwords, wordnet\n","from nltk.stem import WordNetLemmatizer\n","from nltk.stem import SnowballStemmer\n","from google.colab import drive\n","\n","nltk.download('perluniprops')\n","nltk.download('nonbreaking_prefixes')\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('wordnet')\n","\n","drive.mount('/content/drive/') \n","data_path = Path('drive/MyDrive/Datathon2022/data/')"]},{"cell_type":"code","source":["def prepare_df(data):\n","\n","  def normalize(text,nlp):\n","    doc = nlp(text)\n","    words = [t.lemma_ for t in doc if not t.is_punct | t.is_stop]\n","    lexical_tokens = [t.lower() for t in words if len(t) > 3 and t.isalpha()]\n","    return lexical_tokens\n","  \n","  def get_wordnet_pos(tag):\n","    if tag.startswith('J'):\n","        return wordnet.ADJ\n","    elif tag.startswith('V'):\n","        return wordnet.VERB\n","    elif tag.startswith('N'):\n","        return wordnet.NOUN\n","    elif tag.startswith('R'):\n","        return wordnet.ADV\n","    else:\n","        return wordnet.NOUN\n","\n","  if data['label'].dtype == 'O':\n","    df_clean = data.groupby(['message'])['label'].apply(lambda x: ','.join(x)).reset_index()\n","    df_clean['label'] = df_clean['label'].str.split(',')\n","    df_clean.reset_index(inplace=True)\n","    df_clean.drop(columns='index',inplace=True)\n","    final_label = []\n","    support_label = []\n","    for index, row in df_clean.iterrows():\n","        if len(set(row['label'])) == 1:\n","            final_label.append(row['label'][0])\n","            support_label.append('strong')\n","        else:\n","            c = Counter(row['label'])\n","            if 'racist' in c.keys() and 'non-racist' in c.keys():\n","                if c['racist'] >= c['non-racist']:\n","                    final_label.append('racist')\n","                    support_label.append('mild')\n","                else:\n","                    final_label.append('non-racist')\n","                    support_label.append('mild')\n","            elif 'racist' in c.keys() and 'unknown' in c.keys():\n","                final_label.append('racist')\n","                support_label.append('mild')\n","            elif 'non-racist' in c.keys() and 'unknown' in c.keys():\n","                final_label.append('non-racist')\n","                support_label.append('mild')\n","    df_clean['final_label']=final_label\n","    df_clean['support_label']=support_label\n","    df_clean = df_clean.loc[:, ['message', 'final_label','support_label']]\n","  else:\n","    df_clean = data\n","    \n","  t = TweetTokenizer()\n","  df_clean['tokenized'] = df_clean['message'].apply(t.tokenize)\n","  df_clean['lower'] = df_clean['tokenized'].apply(lambda x: [word.lower() for word in x])\n","  punc = string.punctuation+'...¿¡..“'\n","  df_clean['no_punc'] = df_clean['lower'].apply(lambda x: [word for word in x if word not in punc])\n","  stop_words = set(stopwords.words('spanish'))\n","  df_clean['stopwords_removed'] = df_clean['no_punc'].apply(lambda x: [word for word in x if word not in stop_words])\n","  df_clean['pos_tags'] = df_clean['stopwords_removed'].apply(nltk.tag.pos_tag)\n","  df_clean['wordnet_pos'] = df_clean['pos_tags'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\n","  wnl = WordNetLemmatizer()\n","  df_clean['lemmatized'] = df_clean['wordnet_pos'].apply(lambda x: [wnl.lemmatize(word, tag) for word, tag in x])\n","  df_clean['lemma_str'] = [' '.join(map(str,l)) for l in df_clean['lemmatized']]\n","  spanish_stemmer = SnowballStemmer('spanish')\n","  df_clean['stemm'] = df_clean['wordnet_pos'].apply(lambda x: [spanish_stemmer.stem(word) for word, tag in x])\n","  df_clean['stemm_str'] = [' '.join(map(str,l)) for l in df_clean['stemm']]\n","  nlp = spacy.load('es_core_news_sm')\n","  df_clean['lemma_spacy'] = df_clean['message'].apply(lambda x: normalize(x,nlp))\n","  df_clean['lemma_spacy_str'] = [' '.join(map(str,l)) for l in df_clean['lemma_spacy']]\n","  tweet_len = []\n","  for index, row in df_clean.iterrows():\n","      tweet_len.append(len(row['lemma_str']))\n","  df_clean['tweet_len'] = tweet_len\n","  df_clean['word_count'] = df_clean['lemmatized'].apply(lambda x: len(str(x).split()))\n","\n","  return df_clean"],"metadata":{"id":"Dx48l2L-NADg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train = pd.read_csv(Path(data_path,'labels_racism.csv'), sep='|', header=0)\n","df_train = prepare_df(df_train)\n","df_train.to_pickle(Path(data_path, 'df_train.pickle'))"],"metadata":{"id":"ptnaz_8pmtA9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_test = pd.read_csv(Path(data_path,'evaluation_sample.csv'), sep='|', header=0)\n","df_test = prepare_df(df_test)\n","df_test.to_pickle(Path(data_path, 'df_test.pickle'))"],"metadata":{"id":"1w5FgNqeRp7R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_paper = pd.read_csv(Path(data_path, 'paper_input_tweets.csv'), sep='|', header=0)\n","df_paper = df_paper.rename(columns={'text': 'message', 'target': 'label'})"],"metadata":{"id":"-8KUhEtz41U-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_paper = df_paper.drop('Unnamed: 0', axis=1)\n","df_paper = prepare_df(df_paper)\n","df_paper.to_pickle(Path(data_path, 'df_paper.pickle'))"],"metadata":{"id":"huiHnNU7cz08"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_public = pd.read_csv(Path(data_path, 'evaluation_public.csv'), sep='|', header=0)\n","df_public = prepare_df(df_public)\n","df_public.to_pickle(Path(data_path, 'df_public.pickle'))"],"metadata":{"id":"NjnT1fOQMDlu"},"execution_count":null,"outputs":[]}]}